---
title: Building Agents
description: Create AI agents that use tools and reasoning to accomplish complex tasks
---

# Building Agents

AI agents are systems where large language models (LLMs) use tools in a loop to accomplish tasks. The AI SDK provides the `Agent` class and workflow patterns for building powerful agents.

## What are Agents?

Agents are AI systems that:
- Make decisions about which tools to use
- Execute tools in a sequence or loop
- Learn from tool results to make better decisions
- Continue until a goal is achieved

## Agent Class

The AI SDK provides an `Agent` class for building autonomous agents.

### Basic Agent

```ts
import { Agent } from 'ai';
import { createOpenAICompatible } from '@ai-sdk/openai-compatible';

const ollama = createOpenAICompatible({
  name: 'ollama',
  baseURL: 'http://localhost:11434/v1',
});

const agent = new Agent({
  model: ollama('llama3.2'),
  system: 'You are a helpful assistant that can search the web and perform calculations.',,
  tools: {
    search: tool({
      description: 'Search the web',
      parameters: z.object({
        query: z.string(),
      }),
      execute: async ({ query }) => {
        // Search implementation
        return { results: [...] };
      },
    }),
    calculate: tool({
      description: 'Perform calculations',
      parameters: z.object({
        expression: z.string(),
      }),
      execute: async ({ expression }) => {
        // Calculation implementation
        return { result: eval(expression) };
      },
    }),
  },
});

const { text } = await agent.run({
  prompt: 'What is the weather in Tokyo and what is 15 * 24?',
});
```

## Tool Calling

Tools enable agents to interact with external systems.

### Define Tools

```ts
import { tool } from 'ai';
import { z } from 'zod';

const weatherTool = tool({
  description: 'Get the current weather in a location',
  parameters: z.object({
    location: z.string().describe('The city and state'),
    unit: z.enum(['celsius', 'fahrenheit']).optional(),
  }),
  execute: async ({ location, unit = 'fahrenheit' }) => {
    // Call weather API
    const response = await fetch(
      `https://api.weather.com?location=${location}&unit=${unit}`
    );
    return response.json();
  },
});
```

### Use Tools with generateText

```ts
import { generateText, tool } from 'ai';
import { createOpenAICompatible } from '@ai-sdk/openai-compatible';
import { z } from 'zod';

const ollama = createOpenAICompatible({
  name: 'ollama',
  baseURL: 'http://localhost:11434/v1',
});

const { text, toolCalls } = await generateText({
  model: ollama('llama3.2'),
  prompt: 'What is the weather in San Francisco?',
  tools: {
    getWeather: tool({
      description: 'Get the weather in a location',
      parameters: z.object({
        location: z.string(),
      }),
      execute: async ({ location }) => {
        return { temperature: 72, condition: 'sunny' };
      },
    }),
  },
  maxToolRoundtrips: 5, // Allow multiple tool calls
});
```

## Multi-Step Workflows

### Agentic Loop

```ts
import { generateText, tool } from 'ai';
import { createOpenAICompatible } from '@ai-sdk/openai-compatible';

const ollama = createOpenAICompatible({
  name: 'ollama',
  baseURL: 'http://localhost:11434/v1',
});

const result = await generateText({
  model: ollama('llama3.2'),
  prompt: 'Research the history of San Francisco and summarize it',
  tools: {
    search: searchTool,
    scrape: scrapeTool,
  },
  maxToolRoundtrips: 10,
  onStepFinish: ({ text, toolCalls, toolResults }) => {
    console.log('Step completed');
    console.log('Tool calls:', toolCalls);
    console.log('Results:', toolResults);
  },
});
```

## Loop Control

### Stop Conditions

Control when the agent stops executing.

```ts
import { generateText, stepCountIs } from 'ai';

const result = await generateText({
  model: ollama('llama3.2'),
  tools: { search: searchTool },
  prompt: 'Find information about AI',
  stopWhen: stepCountIs(5), // Stop after 5 steps
});
```

### Custom Stop Logic

```ts
const result = await generateText({
  model: ollama('llama3.2'),
  tools: { search: searchTool },
  prompt: 'Find information',
  stopWhen: ({ text, toolCalls }) => {
    // Custom stop condition
    return text.includes('DONE') || toolCalls.length === 0;
  },
});
```

## Configuration Options

### Call Options

Pass runtime configuration to agents.

```ts
type AgentOptions = {
  userId: string;
  maxBudget: number;
};

const agent = new Agent<AgentOptions>({
  model: ollama('llama3.2'),
  tools: {
    purchaseTool: tool({
      description: 'Purchase an item',
      parameters: z.object({
        item: z.string(),
        price: z.number(),
      }),
      execute: async ({ item, price }, { userId, maxBudget }) => {
        if (price > maxBudget) {
          throw new Error('Exceeds budget');
        }
        // Process purchase
      },
    }),
  },
});

const result = await agent.run({
  prompt: 'Buy a laptop',
  options: {
    userId: 'user-123',
    maxBudget: 1000,
  },
});
```

## Advanced Patterns

### RAG Agent

Combine retrieval and generation.

```ts
import { generateText, tool } from 'ai';
import { embed } from 'ai';
import { createOpenAICompatible } from '@ai-sdk/openai-compatible';

const ollama = createOpenAICompatible({
  name: 'ollama',
  baseURL: 'http://localhost:11434/v1',
});

const ragAgent = async (query: string) => {
  // Generate embedding for query
  const { embedding } = await embed({
    model: ollama.embedding('nomic-embed-text'),
    value: query,
  });

  // Search vector database
  const documents = await vectorDB.search(embedding, { topK: 5 });

  // Generate answer with context
  const { text } = await generateText({
    model: ollama('llama3.2'),
    system: 'Answer based on the provided documents.',
    messages: [
      {
        role: 'user',
        content: `Documents:\n${documents.join('\n\n')}\n\nQuestion: ${query}`,
      },
    ],
  });

  return text;
};
```

### Multi-Agent System

Coordinate multiple specialized agents.

```ts
const researchAgent = new Agent({
  model: ollama('llama3.2'),
  system: 'You are a research specialist.',
  tools: { search: searchTool, scrape: scrapeTool },
});

const writingAgent = new Agent({
  model: ollama('llama3.2'),
  system: 'You are a writing specialist.',
  tools: { grammar: grammarTool, style: styleTool },
});

const coordinatorAgent = new Agent({
  model: ollama('llama3.2'),
  tools: {
    research: tool({
      description: 'Research a topic',
      parameters: z.object({ topic: z.string() }),
      execute: async ({ topic }) => {
        const result = await researchAgent.run({ prompt: topic });
        return result.text;
      },
    }),
    write: tool({
      description: 'Write content',
      parameters: z.object({ content: z.string() }),
      execute: async ({ content }) => {
        const result = await writingAgent.run({ prompt: content });
        return result.text;
      },
    }),
  },
});
```

## Error Handling

Handle errors in agent execution.

```ts
const result = await generateText({
  model: ollama('llama3.2'),
  tools: {
    riskyTool: tool({
      description: 'A tool that might fail',
      parameters: z.object({ input: z.string() }),
      execute: async ({ input }) => {
        try {
          // Risky operation
          return await apiCall(input);
        } catch (error) {
          // Return error message to the agent
          return { error: error.message };
        }
      },
    }),
  },
  prompt: 'Use the risky tool',
  onStepFinish: ({ toolResults }) => {
    toolResults.forEach(result => {
      if (result.error) {
        console.error('Tool failed:', result.error);
      }
    });
  },
});
```

## Best Practices

1. **Clear tool descriptions**: Help the model understand when to use each tool
2. **Validate inputs**: Use Zod schemas to ensure type safety
3. **Set stop conditions**: Prevent infinite loops with `maxToolRoundtrips`
4. **Handle errors gracefully**: Return error messages to the agent
5. **Monitor execution**: Use callbacks to track agent behavior
6. **Optimize tool calls**: Minimize expensive operations
7. **Test thoroughly**: Agents can behave unpredictably
